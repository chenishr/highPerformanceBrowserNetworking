##	第二章、构建 TCP 块

互联网的两个核心协议是 IP 和 TCP 协议。IP，即网际协议，提供主机到主机之间的路由和寻址功能；TCP，即传输控制协议，主要是在不可靠的通道中提供可靠的网络传输。TCP/IP 也通常被成为网络协议套件，它是 Vint Cerf 和 Bob Kahn 1974 年在他们的论文“网络通讯协议包”中首次被提出来的。

最初的提议（RFT 675）已经被修改过好几次了，到 1981 年的 V4 版的规格被拆分成两个 RFC：

*	RFC 791	——	网际协议

*	RFC 793	——	传输控制协议

从那以后，TCP 有许多许多改进的建议，但其核心操作却没有明显的改变。TCP 迅速替换掉的其它协议，现在成为许多流行应用的协议，如万维网，电子邮件，文件传输等等。

TCP 在一个不可靠的通道上有效地抽象了一个可靠的网络，为我们的应用隐藏的许多复杂的网络通讯：丢失重传，顺序到达，拥塞的控制与避免，数据的完整性等等。当你使用 TCP 流时，你会得到保证，所发送的每一个字节都会被接收到，并且它们会按顺序的到达客户端。因此，TCP 是优化了准确的交付，但并不是及时的。结果是，当在浏览器中进行网络性能优化时会有不少挑战。

HTTP 标准并没有指定 TCP 作为唯一的传输协议。如果你想要，你可以使用 UDP （用户数据包协议）或者任何其它传输协议来传输 HTTP 。但实际上，今天互联网上所有的 HTTP 流量都是通过 TCP 来传输的，因为它有许多很棒的特性。

正因如此，了解一些 TCP 的核心机制是搭建一个体验好的网站的重要知识。你不用在你的应用中直接和 TCP 打交道，但是你在应用层面所做的选择会决定 TCP 的性能和应用底层的交互。

>	<h5>IP 和 TCP 协议相互交织的历史</h5>

>	我们的知道 IPv4 和 IPv6，但是那些 IPv{1,2,3,5} 呢？4 在 IPv4 中代表的是 TCP/IP 的第四个版本，它是在 1981 年发布的。原始的 TCP/IP 提案是这两个协议的集合，到第四版本草案中正式将其拆分成两个 RFC 。因此，IPv4 中的 v4 和 TCP 并没有继承关系，它独立于 IPv1，IPv2，IPv3 协议。

>	在 1994 年，当工作组开始进行“下一代网际协议”的工作时，需要一个新的版本号，但是 v5 已经分配给了一个实验性的协议：网络流协议（ST）。结果是，ST 从没有使用过，这就是为什么很少听到它。因此，这就有了 IPv6 。

###	三次握手

所有的 TCP 链接都是以三次握手（图 2-1）开始的。在客户端或者服务器能够交换任何数据之前，通信双方必须对开始同步数据包序号以及一些其它的连接变量进行确认。出于安全的考虑，同步序号由双方随记产生。

>	<h5>SYN</h5>

>	客户端随记选择一个同步序号 x 来发送一个 SYN 数据包，这可以携带额外的 TCP 标识和选项。

>	<h5>SYN ACK</h5>

>	服务器将 x 增加 1 ，在随机产生一个同步序号 y ，加上它的标示和选项，向客户端发送响应。

>	<h5>ACK</h5>

>	客户端将 x 和 y 分别增加 1 ，然后想服务器发送 ACK 数据包来完成三次握手。

![figure 2-1][figure21]

######	图 2-1	三次握手

一旦三次握手完成以后，应用数据就可以在客户端和服务器之间传输了。客户端在发送完 ACK 之后就可以马上数据了，但服务器必须在收到 ACK 之后才能发送数据。每个 TCP 连接都必须经过这个启动过程，对于所有使用 TCP 的网络应用程序来说，这包含了一个非常重要的优化暗示：每个连接在发送任何应用数据之前，都必须消耗一个完整的往返延迟。

例如，假设我们的客户端在纽约，服务器在伦敦，我们通过光纤来启动一个新的 TCP 连接，那么三次握手至少消耗掉 56 毫秒的时间（表 1-1）：数据包单向的传输时间是 28 毫秒，之后在返回纽约。要注意到，带宽在这里不起任何作用。相反，这里的时延是在客户端与服务器之间的延迟造成的，也就是纽约到伦敦的传播时延。

进行三次握手所带来的延迟使创建新的 TCP 链接显得相当昂贵，这也是为什么连接重用是那些基于 TCP 的应用的一个重要的优化方案。

>	<h5>快速打开 TCP</h5>

>	TCP 握手已经成为浏览器总延迟中的一个重要的根源，很大程度上是因为数十到数百的不同服务器请求很短的 TCP 流。

>	快速打开 TCP （TFO）是一个旨在减少由于创建新 TCP 连接而引入的延迟的机制。根据谷歌完成的流量分析和网络仿真，研究人员展示了 TFO （它允许在 SYN 包中传输数据）可以减少 15% 的 HTTP 网络传输延迟，平均减少超过 10% 的整页加载时间，在某些情况下减少高达 40% 的高延迟场景。

>	在 3.7+ 的 Linux 内核中同时支持客户端和服务器端 TFO ，这样会给新的客户端和服务器提供很多选项。话虽如此，TFO 并非所有问题的解决方案。虽然它可以消除三次握手所带来的延迟，但这也是在特定的情况下才起作用：在 SYN 包中的有效负载是有最大限制的，只有某些类型的 HTTP 请求才会被发送，由于加密 COOKIE 的缘故，它只在重复的连接中生效。要详细讨论 TFO 的功能和限制，请查阅 IETF 最新的 “快速打开 TCP”。

###	拥塞避免与控制

在 1984 年初，John Nagle 记录了一条被称为“拥塞崩溃”的条件，它会影响到所有的两个结点间具有非对称带宽流量的网络：

>	在复杂的网络中，拥塞控制是一个公认的问题。我们发现，国防部门的网际协议（IP），一个纯粹的数据报协议，和传输控制协议（TCP），一个传输层的协议，当一起使用时，就会导致由于传输层和数据电报层交互而引发的罕见的拥塞问题。特别地，IP 网关容易受到我们称之为“拥塞崩溃”的现象，尤其连接这两个不同带宽的网络的网关...

>	要是往返时间超过了任何主机的最大传播间隔，那么主机就会发送越来越多的相同数据电报的拷贝进入网络。这时网络就会变得非常糟糕。最后所有交换结点的可用缓存都会耗完，数据包必须被丢弃。现在数据包的往返时间处于最大值。主机的每个数据包都会发送几次，最后每个数据包的一些拷贝会到达它的目的地。这就是拥塞崩溃！

>	这个条件是稳定的。一旦达到了饱和点，如果选择丢弃包的算法失败，网络就会在一个退化的状态下持续运行。

>	—— John Nagle RFC 896


这报告推断说 APPANET 就不会有拥塞崩溃这种问题，因为它大多数的节点都有统一的带宽，并且主干网会有额外的容量。但是所有的这些断言的真实性并没有持续多久。在 1986 年，网络上的各种节点迅速增加，一系列的拥塞崩溃事件席卷整个网络——在某些情况下，网络的容量降低了 1000 倍，网络变得不可用。

为了解决这些问题，在 TCP 中实现了多种机制来进行速率管理，这样数据在两个方向都可以发送：流量控制、拥塞控制和拥塞避免。

>	阿帕网（ARPANET）是现代网络的前身，也是世界上最先可运作的分组交换网络。该项目在 1969 年正式启动，在 1983 年时，TCP/IP 协议取代了更早的 NCP（网络控制程序）而成为主要的通信协议。其余的，正如他们所说的那样，已经成为历史了。

####	流量控制

流量控制是这样的一个机制，它防止发送者发送超出接收者处理能力的数据量：接收者可能忙碌，可能处于高负载状态，也可能是只有有限的缓存空间。为了解决这个问题，TCP 连接的每一端都要广播它的接收窗口（RWD）（图 2-2），通过交换可用缓存空间的大小信息来控制到来的数据。

当连接初次建立时，双方都使用系统的默认设置来初始化它们各自的接收窗口的值。一个典型的 Web 页面的大多数数据都是从服务器流向客户端，使得客户端的接受窗口几乎到达瓶颈。然而，如果客户端将大量的数据流向服务器，例如上传图片或者视频文件，那么服务器的接收窗口可能是一个限制因素。

不管什么理由，如果其中一方无法跟上，那么它就会广播一个更小的窗口给发送者。如果窗口大小为零，这就说明不再发送任何数据，一直到应用层将存在缓存空间的数据清掉为止。这种工作流一直存在每个 TCP 连接的生存期：每一边的每个 ACK 包都会携带最新的接收窗口信息，这样可以动态地调整数据流的容量和发送者与接收者的处理速度。

![figure 2-2][figure22]

######	图 2-2	广播接收窗口的大小

>	<h5>窗口扩缩（RFC 1323）</h5>

>	原始的 TCP 规格中设置了广播接收窗口的大小为 16 位，这设置了一个发送者和接收者广播上限最大值（2^16，或者是 65535 位）。结果是，这个上限通常不能获得最佳的性能，特别是在那些显示高带宽延迟产品的网络中；在[“带宽延迟产品”][delay-product]可以了解更多。

>	为了解决这个问题，RFC 1323 被设计成提供一个“TCP 窗口扩缩”选项，它可以允许我提升最大的接收窗口大小到 65535 bit 至 1Gb 。窗口扩缩选项在进行三次握手的时候进行交流，在以后的 ACK 中将会携带一个代表窗口向左移动大小的数值。

>	现在在所有主流的平台上 TCP 窗口扩缩默认是启用的。然而，中间节点、路由器和防火墙可以重写甚至完全去除这个选项。如果你到服务器或者客户端的连接不能完全使用可用带宽，那么检查你的窗口大小的交互会是一个好的开始。在 Linux 平台，窗口扩缩设置可以通过以下命令来检查和启用：

	>	*	$> sysctl net.ipv4.tcp_window_scaling

	>	*	$> sysctl -w net.ipv4.tcp_window_scaling=1

####	慢开始 

尽管在 TCP 中有流量控制，在 1980 年中后期网络拥塞崩溃还是成为一个真实的问题。问题是流量控制能够防止发送方压倒接收方，但却没有一个防止双方压倒网络的机制：发送方和接收方都不知道在连接开始时的可用带宽，因此需要一个机制来评估它，并且根据不断变化的网络条件来调整他们的速度。

为了说明这种调整是有效的，想象一下你在家正在以最大的网速从远程服务器那里下载一个很大的视频文件，这时在你家庭网络的另一个用户打开了一条新连接来下载软件更新。突然之间，你下载视频的速度会变得很慢，那视频服务器必须调整它的数据速率。否则，如果它保持原来的速率，那数据就会堆积在某一个中间的网关，数据包会被丢弃，这会导致网络很低效。

在 1988 年，Van Jacobson 和 michael J.Karels 记录了几个用来解决这些问题的算法：慢开始，拥塞避免，快重传和快恢复。这四个算法很快就被强制成为 TCP 规格的一部分了。事实上，正是这些更新到 TCP 的算法的广泛使用防止了在 80 年代到 90 年代中呈现指数增长的流量的网络的崩溃。

要了解慢开始，最好是看它的实际应用。那么，同样地，让我们回到位于纽约的客户端，它企图检索一个在伦敦服务器的文件。一开始，三次握手表现良好，在这过程中双方通过 ACK 包（图 2-2）广播他们各自的接收窗口大小。一旦最后的 ACK 包发送出去之后，我们就可以交互应用数据了。

唯一的能够评估服务器与客户端之间的有效容量的方法是通过交换数据来测量它，而这正是慢开始被设计来做的事情。一开始，该服务为每一个 TCP 连接初始化一个拥塞窗口变量，并将它所初始值设为一个保守的，由系统指定的值（在 Linux 上是 initcwnd）。

拥塞窗口大小（cwnd）

>	发送方能够发送出去的但还没有收到ACK确认的最大数据报文段长度

cwnd 变量不会在发送方和接收方之间广播或者交换——在这个例子中，它是一个由伦敦服务器维护的私有变量。之前已经介绍过：在客户端与服务器之间的发送出去的最大值（没收到 ACK 确认）是 rwnd 和 cwnd 变量的最小值。到目前为止还不错，但是服务器和客户端是如何确定他们拥塞窗口的最优值的呢？毕竟，网络的状态时刻都在发生变化，甚至在两个相同的网络结点中,正如我们之前的一个例子一样。如果我们可以使用算法而不是手工的调整每个连接的窗口大小就太好了。

解决方法是先慢慢发送，待数据包确认之后再增加窗口大小，这就是慢开始！最初 cwnd 设置的开始值为 1 报文段；在 1999 年 4 月份的时候，RFC 2581 将这个值的最大值更新为 4 个报文段，而 2013 年 4 月份时，RFC 6928 再次将这个值增加到 10 个报文段。

一个新 TCP 连接的在发送中的数据的最大值是 rwnd 和 cwnd 的最小值；因此服务器可以连续发送 4 个报文段给客户端，然后就必须停止发送并等待确认。然后，对于每一个已经接收到的 ACK，慢开始算法表明，服务器可以为它的 cwnd 窗口大小增加一个报文段 —— 对于每个被确认的数据包，可以发送两个新的数据包。在这个阶段的 TCP 连接被称为“指数增长”算法（图 2-3），因为服务器和客户端都尝试快速地覆盖它们之间的网络路径的有效带宽。

![Round Trips][figure23]

#####	图 2-3 拥塞控制和拥塞避免

那么为什么在我们为浏览器搭建应用的时候慢开始是一个重要的因素呢？是这样的，HTTP 和其它的应用层协议工作于 TCP 之上，无论带宽如何，每一个 TCP 链接都必须经过慢开始这个阶段 —— 我们不能一开始就能使用连路的全部容量。

相反，我们以一个很小的拥塞窗口开始，然后每次往返都将其翻倍——也就是指数增长。结果是，达到某个特定的吞吐量目标所需要的时间是一个客户端和服务器之间的往返时间和初始拥塞窗口的大小的函数方程。

#####	方程式 2-1 达到 cwnd 为 N 时所需要的时间

	\begin{aligned} \mathrm{Time} = \mathrm{RTT} \times \left\lceil log_2 \left( \frac{\mathrm{N}}{\mathrm{initial\ cwnd}} \right) \right\rceil \end{aligned}

手动演示慢开始的影响，让我们假设下列情景：

*	客户端和服务器的接收窗口：65535 bytes（64 kB）

*	初始拥塞窗口：4 报文段（RFC 2581）

*	往返时间：56 ms（伦敦到纽约）

我们本例和接下来的示例中使用旧的（RFC 2581）初始拥塞窗口的值，即 4 报文段，对于大多数服务来说它仍然是一个常见的值。除非你不犯这种错误，不是吗？通过下面例子的演示，你可能觉得你有必要去更新你的服务器了！

尽管接收窗口（rwnd）大小大小设置为64 KB，但一个新 TCP 连接的初始吞吐量是受限于拥塞窗口的大小的。事实上，要达到 64KB 的限制，我们需要将拥塞窗口增加到 45 报文段，这需要耗费 224 ms：

	\[ \begin{aligned} \frac{65,535\ \mathrm{bytes}}{1,460\ \mathrm{bytes}} &\approx 45\ \mathrm{segments} \\ 56\ \mathrm{ms} \times \left\lceil log_2 \left( \frac{45}{4} \right) \right\rceil &= 224\ \mathrm{ms} \end{aligned} \]

在客户端与服务器之间达到 64KB 的吞吐量，这需要 4 个往返（图 2-4），几百毫秒的延迟！因此事实上，对于一些客户端和服务端可以达到 Mbps+ 的连接，这对慢开始没有任何效果。

![拥塞窗口的增长][figure24]

#####	拥塞窗口的增长

要减少增长到拥塞窗口所花费的时间，我们可以减少客户端到浏览器的往返时间——也就是说，在地理上将服务器移近客户端。或者我们将拥塞窗口大小初始化为 RFC 6928 所定义的 10 个报文段。

慢开始对于大数据流的下载并不是大问题，因为客户端和服务器会在数百毫秒之内就将窗口大小增长到最大值，并且持续地在这最大的速度进行传输数据 —— 慢开始这个阶段所消耗的时间在整个更长的传输时间给平摊了。

然而，对于许多的突发的和短的 HTTP 连接来说，在还没达到最大窗口大小就终止是很常见的。结果是，大多数的 Web 应用的性能通常受限于服务器与浏览器之间的往返时间：慢开始限制了有效带宽的吞吐量，这对小量传输的性能有不好的影响。

>	慢开始重启

>	为了调节新链接的传输率，TCP 同样实现了慢开始重启机制（SSR），当它闲置时间达到一个设定的值的时候，这个机制就会重置连接的拥塞窗口。原理很简单：当连接闲置的时候网络状态可能已经改变了，为了避免拥塞，窗口大小会被重置为一个“安全”的默认值。

>	很明显，SSR 对于那些可能经常闲置的长连接会有很大的影响 —— 即 HTTP keep-alive 连接。结果是，在服务器端建议禁用 SSR 。在 Linux 平台上，SSR 设置可以通过以下命令进行查看与禁用：

	>	$> sysctl net.ipv4.tcp_slow_start_after_idle

	>	$> sysctl -w net.ipv4.tcp_slow_start_after_idle=0






[figure21]:	../images/ch02/hpbn_0201.png	"三次握手"
[figure22]:	../images/ch02/hpbn_0202.png	"广播接收窗口的大小"
[figure23]:	../images/ch02/hpbn_0203.png	"拥塞控制和拥塞避免"
[figure24]:	../images/ch02/hpbn_0203.png	"拥塞窗口的增长"
[delay-product]:	http://tools.loc/High%20Performance%20Browser%20Networking/chimera.labs.oreilly.com/books/1230000000545/ch02.html#BANDWIDTH_DELAY_PRODUCT
