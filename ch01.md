##	第一章、初识延迟与带宽

###	速度就是特性

近几年来，网络性能优化（WPO）的出现与快速发展，已经成为用户追求更快速度、更好体验的一个重要标记。这不仅是这个加速连接的现实中对速度的情感需求，更是由在线商务对性能底线衡量结果的需求：

*	更快的网站能让用户更好地参与其中。

*	更快的网站能有更高的回头率。

*	更快的网站能有更高的转换率。

简而言之，速度即特性。而要更快速，我们需要理解在起作用的许多因素和基本限制。本章，我们将会专注于两个决定所有网络性能的要素：延迟和带宽。

延迟
>	从源发送一个数据包到目的的时间。

带宽
>	逻辑或物理通讯的最大吞吐量。

![figure1-1][figure11]

######	图 1-1、延迟与带宽

为了更好地了解延迟与带宽一起是如何工作的，我们会使用工具来进一步了解 TCP、UDP和所有基于它们的协议的内部构件和性能特性。

>	<h5>低时延的跨大西洋高速光缆工程</h5>

>	在高频交易的金融市场中，延迟是一个重要的标准，一个很少的差别或毫秒级的延迟也会导致巨大的损失。

>	在 2011 年初，华为和爱尔兰部署一条全新的横跨大西洋的光纤电缆，连接伦敦和纽约。其目标是，与其他现存的线路相比，以更短的路由为交易员节省 5 毫秒的延迟。

>	一旦完成部署，它只会被适用于金融行业。该光纤将会耗资4亿美元，一毫秒的代价是80001万美元。延迟的代价是昂贵的，超出想象。

###	影响延迟的因素

延迟是一个消息或者说数据包从源被传送到目的所用的时间。这是一个简单而实用的定义，但却隐藏的大部分有用的信息：一个系统通常包含许多的源或者组件，每发送一个消息，它们都会耗费一定的时间。了解有那些组件和那些决定着性能很重要。

让我们来分析以下，在一个网络典型的路由中，有那些常规的组件，而那些是对性能起着决定性作用的：

*	传播时延
>	一个数据包在从发送方到接收方所需的时间，这是一个距离除以信号传输速度的函数。

*	发送时延
>	将数据包全部发送到链路的时间，这是一个数据包长度除以发送速率的函数。

*	处理时延
>	节点处理数据包头所需要的时间，例如检查位错误、确定数据包的目的地。

*	排队时延
>	数据包在输入队列中等待处理的时间。

在客户端到服务器之间的总时延就是以上所列时延的总和。传播时延是由传播的距离和信号传输的媒介来决定的。正如我们所知道的那样，传播速度通常是一个很小的光速常量因子。然而，发送时延则是由发送速率决定的，和传播的距离没有关系。举个例子，假设我们要通过两个链路发送一个 10Mb 的文件：一个链路的发送速率是 1Mbps，另一个的是 100Mbps。在前一个链路中，将文件全部发送到链路上需要 10 秒钟，而在后一个链路中只需要 0.1 秒。

接着，数据包到达路由器时，路由器会检查数据包头来决定下一个路由，也会进行其它的检查——这些都是会消耗时间的。大部分的这些逻辑都已经固化到硬件上了，所以时延会很小，但它还是存在的。最后，如果数据包到达速度大于路由器的处理速度，那么数据包就会排队到一个输入缓存中。数据包在缓存中所消耗的时间，毫无疑问，正是传说中的排队时延。

数据包在网络上传播时会触发很多次这些时延。两个端点之间的距离越远，传播时延就会越长。在传播中经过越多的路由器，每个数据包所需要的处理时延和发送时延就会越多。最后，链路上的流量越高，数据包在输入缓存中的排队时延就越长。

>	<h5>本地路由的缓存臃肿</h5>

>	缓存臃肿是一个由 Jim Gettys 在 2010 年创建和普及的术语，这是一个描述排队时延对网络性能的影响的很好的例子。

>	现在的问题是，许多路由器为了避免网络丢包而配置了大量的接收缓存。然而，这样做会破坏了 TCP 拥塞避免机制（这将会在下一章讲述），并且引入了高可变的网络延迟。

>	好消息是，新的 CoDel 主动队列管理算法可以解决这个问题，该算法已经在 3.5+ 的 Linux 内核中实现了。要了解更多，情参考 ACM 队列的“[控制队列时延][aqmacm]”。

###	光速与传播延迟

正如爱因斯坦的狭义相对论所描述的那样，光速是所有的能量、物质和信息所能达到的最大速度。这是一个所有网络数据包传播时间的很明显的限制。

光速很快，高达 299,792,458 米每秒，或者说是 186,282 英里每秒，这是好消息。然而，凡事总有然而，那是光线在真空中的速度。我们的数据包是通过媒介来传播的，如同轴电缆或者光纤，这会降低信号的速度（表1-1）。光波的速度与数据包在媒介的速度之比就是该媒介的折射率。折射率越大，光波的传播速度越小。

数据包长途传播所使用的光纤，其典型的折射率的值会在 1.4 到 1.6 之间。人们正在一步一步地改善传播媒介的质量和降低其折射率。但为了简单起见，经验法则是假设光波在光纤的传播速度为 200,000,000 米每秒，相应的折射率约为 1.5 。所幸者，我们已经可以达到这样的一个高速了。感谢那些伟大的工程师。

表1-1 信号分别在真空和光纤中的延迟
<table>
	<tr>
		<th>路由</th>
		<th>距离</th>
		<th>真空中的延迟</th>
		<th>光纤中的延迟</th>
		<th>光纤中的往返时间（RTT）</th>
	</tr>
	<tr>
		<td>纽约到旧金山</td>
		<td>4,148 km</td>
		<td>14 ms</td>
		<td>21 ms</td>
		<td>42 ms</td>
	</tr>
	<tr>
		<td>纽约到伦敦</td>
		<td>5,585 km</td>
		<td>19 ms</td>
		<td>28 ms</td>
		<td>56 ms</td>
	</tr>
	<tr>
		<td>纽约到悉尼</td>
		<td>15,993 km</td>
		<td>53 ms</td>
		<td>80 ms</td>
		<td>160 ms</td>
	</tr>
	<tr>
		<td>赤道周长</td>
		<td>40,075 km</td>
		<td>133.7 ms</td>
		<td>200 ms</td>
		<td>200 ms</td>
	</tr>
</table>

光的速度很快，但它在纽约和悉尼之间往返一次也需要 160 ms 。实际上，表1-1 中的数据是相当乐观的，因为这是在假设数据包经过的光纤在两个城市之间是沿着最大圆路径来铺设的（球面上两点之间的最短距离）这一前提下的数据。现实却不是这样子的，数据包会经过更长的路由。并且还会引入更多的发送时延、传播时延、处理时延和排队时延。结果是，在纽约和悉尼之间的实际时间会在 200 - 300 毫秒之间。所有的情况都考虑了，这仍然很快，不是吗？

我们日常的时间测量中并不习惯于用毫秒来做单位，但是研究表明，系统一旦有超过 100 -200 毫秒的延迟时，我们就会察觉到的。如果超过了 300 毫秒的临界值，这交互就被认为是“缓慢”了，再超过 1000毫秒（1秒）的界限时，很多用户在等待响应的过程中已经进行了心理上下文切换——也许开始白日梦，也许想到下一个紧急任务了。

结论很简单：为了是我们的用户有更好的体验及让他们集中于当前的任务，我们的应用需要在数百毫秒之内做出响应。这并没有留给我们太多的错误空间，特别是在网络上。要达到这一目标，网络延迟必须要重点谨慎管理，并且在开发过程的每一个阶段都需要有明确的设计标准。

>	内容分发网络（CDN）服务提供了许多优势，它主要的一点是将内容分布到全球各地，然后就附近的内容为客户端提供服务，这样会大大地减少所有数据包的传播时延。

>	我们也许不能使得数据包传播的更快，但我们可以将我们的服务战略性地部署到离用户近的地方以减短距离！借助CDN，我们可以为数据传播带来显著的性能提升。

###	最后一英里的延迟

具有讽刺意义的是，实际上并不是在跨越大洲大洋中，而是在最后的几英里产生最多的延迟。	为了将你家或你办公室的电脑连上网，你当地的 ISP 需要在临近的小区组建路由，合并信号，并将其转发到本地路由节点。在实际情况下，根据连接类型、路由方法和部署技术，这连接到你 ISP 主路由的前几跳可能会消耗十几毫秒的时间。根据美国联邦通信委员会（FCC）在 2013 年早期发布的“美国宽带测量”报告，在高峰期：

>	平均来说，在高峰期，光纤到家在延迟方面有最佳的性能，其平均值为 18 毫秒；同轴电缆的是 26 毫秒；而 DSL 的是 44 毫秒。

>	—— FCC 2013 二月

在数据包到达目的地之前，只是到 ISP 的主网络就消耗掉了 18 - 44 毫秒的时间了。FCC 的报告是针对美国的，但是那最后几英里的延迟，对于所有的不管地理互联网服务商来说都是一个挑战。如果你好奇，一个简单的程序 traceroute ，可以了解互联网服务商的拓扑和性能。

	$> traceroute google.com
	traceroute to google.com (74.125.224.102), 64 hops max, 52 byte packets
	 1  10.1.10.1 (10.1.10.1)  7.120 ms  8.925 ms  1.199 ms 1
	 2  96.157.100.1 (96.157.100.1)  20.894 ms  32.138 ms  28.928 ms
	 3  x.santaclara.xxxx.com (68.85.191.29)  9.953 ms  11.359 ms  9.686 ms
	 4  x.oakland.xxx.com (68.86.143.98)  24.013 ms 21.423 ms 19.594 ms
	 5  68.86.91.205 (68.86.91.205)  16.578 ms  71.938 ms  36.496 ms
	 6  x.sanjose.ca.xxx.com (68.86.85.78)  17.135 ms  17.978 ms  22.870 ms
	 7  x.529bryant.xxx.com (68.86.87.142)  25.568 ms  22.865 ms  23.392 ms
	 8  66.208.228.226 (66.208.228.226)  40.582 ms  16.058 ms  15.629 ms
	 9  72.14.232.136 (72.14.232.136)  20.149 ms  20.210 ms  18.020 ms
	10  64.233.174.109 (64.233.174.109)  63.946 ms  18.995 ms  18.150 ms
	11  x.1e100.net (74.125.224.102)  18.467 ms  17.839 ms  17.958 ms

在上面的例子中,数据包在桑尼维尔市的圣克拉拉发出，然后奥克兰，回到圣何塞，路由到了“529 Bryant”的数据中心，接着它被路由到谷歌服务器，第11跳到达了目的地。这整个过程中，平均耗时18 ms。所有的事情考虑起来，情况不坏，但同时数据包也基本穿越了整个美国大陆大部分地方。

最后的距离的延迟主要看你 ISP 的情况，其部署的技术，网络的拓扑，甚至是每天的时间段。作为一个最终用户，如果你想改善你的网络速度，择延迟最小的本地 ISP 之很值得的优化方案。

>	延迟，不像带宽，是很多网站的性能瓶颈！要理解其中原理，我们需要理解 TCP 和 HTTP 协议（在随后的章节中会学习）的结构。当然，如果你对此感兴趣，你可以跳转到“[More Bandwidth Does not Mater(Much)][mote-bandwidth]”。

<br />

>	<h5>使用 Traceroute 测量延迟</h5>

>	Traceroute 是一个简单的网络诊断工具，用来记录数据包的路由路径以及路由中每一跳的延迟。为了标识出路由中的每一跳，它以递增的 TTL 发送一系列数据包到目标地址。当 TTL 达到上限，中间路由将返回一个 ICMP 已超时“消息，它就是用这个来衡量每个网络跳的延迟。

>	这个工具在 Unix 平台上是命令 traceroute；在 Windows，它叫做 tracert 。

###	核心网络的带宽

光纤作为一个简单的光的管道，它稍微比头发小一点，被设计在电缆之间传输光线。金属线也可以使用，但它要承受更高的信号丢失，电磁干扰，和更高的维护成本。你可以选择二者之一来传送数据包，但对于距离远的，最好使用光纤链路。

在带宽这方面光纤有另一个优势，因为它通过波分复用可以携带更多的波长（频道）信息。所以，光纤链路的总带宽是每个频道的数据率和频道个数的乘积。

早在 2010 年初，研究人员已经可以复用超过 400 个在峰值容量为每个频道 171 Gbit/s 的波长，单个光纤链路的总带宽超过 70 Tbit/s ！我们需要使用上千根铜线才能达到这样的吞吐量。毫无疑问，大多数的长跳，例如各大洲之间的海底数据传输，现在都是使用光纤来传输的。每条电缆携带几条光纤（一般 4 条），这样每条电缆的带宽就能达到上百 Tb 每秒了。

###	边缘网络的带宽

互联网核心数据路径的主干网（或者说光纤链路）是由上百 Tb 每秒的电缆组成的。然而，在边缘网络的有效容量就会少很多很多，其所依赖的技术参差不齐：拨号，DSL，大量的无线技术，光纤入户，甚至是本地路由器的性能。用户能够达到的带宽是由客户端到目的服务器中容量最低的链路决定的（图1-1）。

阿卡迈科技运营着一个全球 CDN ，它的服务器分布在世界各地，并且他们在阿卡迈的网站上免费提供他们服务器上的平均带宽报告。表1-2 是 2013 年第一季度获取的宏观带宽趋势。

表1-2 2013年第一季度阿卡迈服务器的平均带宽

<table >
	<tr>
		<th>排名</th>
		<th>国家</th>
		<th>平均带宽 Mb/s</th>
		<th>同比增长</th>
	</tr>
	<tr>
		<td>-</td>
		<td>全球</td>
		<td>3.1</td>
		<td>17%</td>
	</tr>
	<tr>
		<td>1</td>
		<td>南韩</td>
		<td>14.2</td>
		<td>-10%</td>
	</tr>
	<tr>
		<td>2</td>
		<td>日本</td>
		<td>11.7</td>
		<td>6.8%</td>
	</tr>
	<tr>
		<td>3</td>
		<td>香港</td>
		<td>10.9</td>
		<td>16%</td>
	</tr>
	<tr>
		<td>4</td>
		<td>瑞士</td>
		<td>10.1</td>
		<td>24%</td>
	</tr>
	<tr>
		<td>5</td>
		<td>新西兰</td>
		<td>9.9</td>
		<td>12%</td>
	</tr>
	<tr>
		<td colspan=4>...</td>
	</tr>
	<tr>
		<td>9</td>
		<td>美国</td>
		<td>8.6</td>
		<td>27%</td>
	</tr>
</table>

前面的数据不包括移动通讯的数据，这个主题我们稍候在做详细的讨论。现在我只想说的是，移动端的速度是高可变的和普遍低速。然而需要注意的是，在 2013 年初全球的平均带宽速度只有 3.1 Mbps ！南韩在世界领先，其平均的吞吐量为 14.2 Mbps，美国以 8.6 Mbps 居第九位。

作为参考，一个高清的流视频根据分辨率和解码器的不同会要求 2 到 10 Mbps 的带宽。因此，平均来说，一个在边缘网络的用户可以观看一个低分辨率的流视频，但这样做会消耗大量的带宽，对于有多个用户的家庭来说这并不是好事。

找出所有用户的带宽瓶颈所在通常是一项伟大并且重要的任务。再次地，如果对此感兴趣，网上有很多测试本地服务上传下载速度的服务，例如，由 Olkla 运营的[speedtest.net][speedtest]网站。我们会在对 TCP 的讨论中看到为什么选择本地服务很重要。运行一个服务的测试能够很好的检测你本地 ISP 的广告是否真实。

![figure1-2][figure12]

######	图 1-2、上传和下载测试（speedtest.net）

然而，当一个高带宽的链路可用时，它也不能保证稳定端对端的性能。网络有可能因为高需求、硬件故障、集中的网络攻击或一大堆其它的原因而导致任何时间任何节点的网络拥挤。高可变的吞吐量和延迟性能是我们数据网络的一个固有的属性，预测、管理和适应不断变化的“网络天气”是一项复杂的任务。

###	提供更高的带宽和更低的延迟

我们对高带宽需求的增长越来越快，很大一部分是由于日益普及的流媒体，这已经超过了总网络流量的一半了。好消息是，虽然它可能不是便宜的，现在有多种策略来提高带宽速度：我们可以增加更多的纤维到光纤链路，我们可以在拥挤的地方增加链路，我们可以在现有的链路上改善波分复用技术以传输更多的数据。

电信市场研究和咨询公司 TeleGeography 估计，截至2011年，我们平均仅使用了部署的海底光纤链路可用容量的20％。更重要的是，在2007年和2011年之间，一半以上的所有新增跨太平洋电缆进行了波分复用技术升级，即在相同的光纤链路中可以传输更多的数据。当然，我们不能指望这些提升无限制地进行下去，因为每一个介质都会达到其收益递减点。尽管如此，只要经济允许，我们没有理由不去增加带宽。即使新技术都失败了，我们还可以部署更多的光纤链路。

从另一方面来说，改善延迟是一件非常不同的事情。改善光纤链路的质量可以使得传播速度稍微的接近光速：更好的低折射率材料和更快的路由器。然而，我们现在的光纤的折射率在 1.5 左右，我们期望从这方面所得到的最大提升只有 30% 。不幸的是我们那物理定律没办法：光速决定的最小延迟。

既然我们不能是光线传播的更快，我们可以缩短距离——地球上任意两点之间最短的距离被定义为它们之间的大圆路径。然而，新电缆不可能完全按照大圆路径来铺设，这关系到地形，社会和政治等因素，当然也受到成本的限制。

结果是，为了提高我们的应用的性能，我们需要在带宽和光速限制的前提下来架构和优化我们的协议和网络码：我们需要减少距离，将数据向客户端靠近，通过缓存、预加载和相关的技术来使我们的应用隐藏延迟，这将会在接下来的章节中解析。


[mote-bandwidth]:	http://tools.loc/High%20Performance%20Browser%20Networking/chimera.labs.oreilly.com/books/1230000000545/ch10.html#MORE_BANDWIDTH_DOESNT_MATTER_MUCH
[aqmacm]:	http://hpbn.co/aqmacm
[speedtest]:	http://speedtest.net
[figure11]:	images/ch01/hpbn_0101.png	"延迟和带宽"
[figure12]:	images/ch01/hpbn_0102.png	"上传和下载测试"
